import os
import time
import numpy as np
import pandas as pd
import joblib

# ===== åŸºæœ¬è¨­å®š =====
MYSQL_HOST = "localhost"
MYSQL_USER = "aict702"
MYSQL_PASSWORD = "aict702@Lab702"
POLICY_DB = "sensorTest"
POLICY_TABLENAME = "leakage_predictions"
DATA_DB = "mm_si"
TABLE_NAME = "si_prs"

# ===== åƒæ•¸ =====
HIGH_ON = 0.2
LOW_END = 0.1
MAX_CYCLE_SEC = 50.0
ID_COL = "si_id"
TIME_COL = "si_ts"
PRESSURE_THRESHOLD = HIGH_ON
OUTPUT_DIR = "cycles_out"
os.makedirs(OUTPUT_DIR, exist_ok=True)

LABEL_MAP = {0: "âœ… æ­£å¸¸", 1: "âš ï¸ æ´©æ¼ï¼ˆ7åœˆï¼‰", 2: "ğŸš¨ æ´©æ¼ï¼ˆ10åœˆï¼‰"}
# LABEL_MAP = {0: "æ´©æ¼ç­‰ç´š0", 5: "æ´©æ¼ç­‰ç´š1", 10: "æ´©æ¼ç­‰ç´š2"}
# LEAKAGE_MAP = {0: 0, 5: 1, 10: 2}
FEATURE_COLS = ["mean", "std", "holding_time", "range"]
POLICY_MAP = {
    0: "ç„¡éœ€ç¶­ä¿®",
    1: "å®‰æ’åœæ©Ÿæª¢æŸ¥èˆ‡æ°£å¯†æ¸¬è©¦",
    2: "ç·Šæ€¥åœæ©Ÿï¼Œç«‹å³ç¶­ä¿®ä¸¦è¿½è¹¤"
}


MODE_MAP = {
    "psr_val_0": "single",
    "psr_val_1": "double",  # æ„Ÿæ¸¬å™¨äºŒ
    "psr_val_2": "single",
    "psr_val_3": "single",
    "psr_val_4": "single",
    "psr_val_5": "single",
}
SENSOR_NAME = {
    "psr_val_0": "sensor1",
    "psr_val_1": "sensor2",
    "psr_val_2": "sensor3",
    "psr_val_3": "sensor4",
    "psr_val_4": "sensor5",
    "psr_val_5": "sensor6",
}
MODEL_PATH = "models/rf_multioutput.pkl"

# ===== æ™‚é–“ & è³‡æ–™æµ =====
def _to_datetime(val):
    try:
        ts = pd.to_datetime(val, errors="coerce")
        if pd.notna(ts): return ts
    except Exception:
        pass
    try:
        f = pd.to_numeric(val, errors="coerce")
        if pd.isna(f): return None
        if f > 1e15:   return pd.to_datetime(f, unit="ns", errors="coerce")
        elif f > 1e14: return pd.to_datetime(f, unit="us", errors="coerce")
        elif f > 1e11: return pd.to_datetime(f, unit="ms", errors="coerce")
        elif f > 1e9:  return pd.to_datetime(f, unit="s",  errors="coerce")
        else:          return pd.to_datetime(f, unit="s",  errors="coerce")
    except Exception:
        return None

def simulate_data_stream():
    df = pd.read_csv('row_data/ä¸€æ ¹/7åœˆ/ç¬¬ä¸‰æ ¹ä¸ƒåœˆ_1.csv', encoding="utf-8-sig")
    for _, row in df.iterrows():
        record = {
            'si_ts': _to_datetime(row['si_ts']),
            'psr_val_0': float(row['psr_val_0']),
            'psr_val_1': float(row['psr_val_1']),
            'psr_val_2': float(row['psr_val_2']),
            'psr_val_3': float(row['psr_val_3']),
            'psr_val_4': float(row['psr_val_4']),
            'psr_val_5': float(row['psr_val_5']),
        }
        # time.sleep(0.02)
        yield record

# ===== é€ç­†åˆ‡é€±æœŸï¼ˆä¿ç•™ä½ çš„ç‰ˆæœ¬ï¼‰ =====
class CycleDetector:
    """
    é€ç­†åµæ¸¬é€±æœŸï¼ˆå³æ™‚ä¸²æµï¼‰
    - ä¸€èˆ¬æ¨¡å¼: mode="single"/"double" (åŸé‚è¼¯)
    - å›ºå®šé•·åº¦æ¨¡å¼: fixed_duration_sec>0 â†’ åªè¦åµæ¸¬åˆ° ä½â†’é«˜ï¼Œå°±å¾ã€Œæœ€å¾Œä¸€ç­†ä½å£“é»ã€èµ·ç®— fixed_duration_sec ç§’ä¸¦åˆ‡æ®µ
    """
    def __init__(self, low_th=0.1, high_th=0.2, sensor_key="psr_val_0", mode="single",
                 max_cycle_sec=None, on_timeout=None, fixed_duration_sec=11.0):
        assert mode in ("single", "double")
        self.low_th = low_th
        self.high_th = high_th
        self.key = sensor_key
        self.mode = mode

        # å³æ™‚è¶…æ™‚å‘Šè­¦ï¼ˆæ²¿ç”¨ï¼‰
        self.max_cycle_sec = max_cycle_sec
        self.on_timeout = on_timeout

        # ---- ramp è¿½è¹¤ï¼ˆæ–°ç‰ˆï¼‰----
        self.in_low = False
        self.last_low_rec = None   # ä½å£“å€æœ€å¾Œä¸€ç­†ï¼ˆ<low_thï¼‰
        self.ramp_start_rec = None # é›¢é–‹ä½å£“å¾Œï¼Œç”¨ last_low_rec ä½œç‚ºèµ·é»

        # ä¸€èˆ¬æ¨¡å¼æ‰€éœ€
        self.state = "IDLE"
        self.cycle_buffer = []
        self.cycle_start_ts = None
        self.timeout_alerted = False

        # å›ºå®šæ™‚é•·æ¨¡å¼
        self.fixed_duration_sec = fixed_duration_sec
        self.fixed_deadline_ts = None
        self.pre_buffer = []   # å·²é›¢é–‹ä½å£“åˆ°å‡ç ´ high_th ä¹‹é–“çš„é»ï¼ˆå« ramp_start_recï¼‰
        self.fixed_state = "IDLE"  # IDLE â†’ ARMED(é›¢ä½å£“ç­‰å¾…å‡ç ´) â†’ ACTIVE(æ”¶é›†åˆ°æˆªæ­¢) â†’ WAIT_LOW

    def _val(self, record): 
        return float(record[self.key])

    def _track_ramp(self, record, val):
        """ç¶­è­· last_low_rec / ramp_start_rec èˆ‡ pre_bufferã€‚"""
        if val < self.low_th:
            # é‚„åœ¨ä½å£“ï¼šæ›´æ–°æœ€å¾Œä¸€ç­†ä½å£“é»ï¼Œæ¸… ramp èˆ‡ pre_buffer
            self.in_low = True
            self.last_low_rec = record
            self.ramp_start_rec = None
            self.pre_buffer = []
        else:
            if self.in_low:
                # å‰›é›¢é–‹ä½å£“ï¼šèµ·é»=æœ€å¾Œä¸€ç­†ä½å£“é»
                self.ramp_start_rec = self.last_low_rec if self.last_low_rec is not None else record
                self.pre_buffer = [self.ramp_start_rec]
                self.in_low = False
            # è‹¥å·²ä¸åœ¨ä½å£“ä¸”å°šæœªå‡ç ´ high_thï¼Œå°‡é»å…ˆæ”¾é€² pre_bufferï¼ˆç‚ºäº†ä¸æ¼æ‰ä¸Šå‡æ®µï¼‰
            if self.ramp_start_rec is not None and val < self.high_th:
                self.pre_buffer.append(record)

    def _maybe_timeout_alert(self, record):
        if self.max_cycle_sec is None or self.cycle_start_ts is None or self.timeout_alerted:
            return
        now_ts = record.get(TIME_COL)
        if pd.isna(now_ts) or pd.isna(self.cycle_start_ts):
            return
        duration = (now_ts - self.cycle_start_ts).total_seconds()
        if duration > self.max_cycle_sec:
            self.timeout_alerted = True
            if callable(self.on_timeout):
                self.on_timeout(self.key, duration, self.cycle_start_ts, now_ts)
            else:
                print(f"âš ï¸ å³æ™‚å‘Šè­¦ï¼š{self.key} ç›®å‰é€±æœŸå·² {duration:.2f}s (> {self.max_cycle_sec}s)")

    # ================= å›ºå®šæ™‚é•·æ¨¡å¼ =================
    def _update_fixed(self, record, val):
        ts = record.get(TIME_COL)

        if self.fixed_state == "IDLE":
            # ç­‰å¾…ï¼šå…ˆé›¢é–‹ä½å£“ â†’ ramp_start_rec æˆç«‹ â†’ å†å‡ç ´ high_th æ‰å•Ÿå‹•
            if (self.ramp_start_rec is not None) and (val >= self.high_th):
                # èµ·é»=æœ€å¾Œä¸€ç­†ä½å£“é»ï¼›çª—å£=èµ·é»æ™‚é–“+fixed_duration
                self.cycle_buffer = list(self.pre_buffer) + [record]
                self.cycle_start_ts = self.ramp_start_rec.get(TIME_COL) if self.ramp_start_rec else ts
                self.fixed_deadline_ts = self.cycle_start_ts + pd.Timedelta(seconds=self.fixed_duration_sec)
                self.timeout_alerted = False
                self.fixed_state = "ACTIVE"
            return None

        if self.fixed_state == "ACTIVE":
            # æ”¶é›†ç›´åˆ°æˆªæ­¢ï¼ˆåŒ…å« <= deadline çš„é»ï¼‰
            if ts <= self.fixed_deadline_ts:
                self.cycle_buffer.append(record)
                # å¯é¸ï¼šä¸€èˆ¬è¶…æ™‚å‘Šè­¦ï¼ˆèˆ‡ fixed_duration ç„¡é—œï¼‰ï¼Œè‹¥æœ‰è¨­å®šä¹Ÿæª¢æŸ¥
                self._maybe_timeout_alert(record)
                return None
            # è¶…éæˆªæ­¢ â†’ è¼¸å‡ºï¼ˆä¸Ÿæ£„è¶…éæˆªæ­¢çš„é€™ç­†ï¼‰
            out = pd.DataFrame([r for r in self.cycle_buffer if r.get(TIME_COL) <= self.fixed_deadline_ts])
            # åˆ‡æ®µå¾Œé€²å…¥ WAIT_LOWï¼šå¿…é ˆå…ˆå›åˆ°ä½å£“ï¼Œå†ä¸‹ä¸€æ¬¡ä½â†’é«˜æ‰æœƒé‡æ–°é–‹å§‹
            self.fixed_state = "WAIT_LOW"
            self.cycle_buffer = []
            self.cycle_start_ts = None
            self.fixed_deadline_ts = None
            self.ramp_start_rec = None
            self.pre_buffer = []
            return out

        if self.fixed_state == "WAIT_LOW":
            # ç­‰å¾…é‡æ–°å›åˆ°ä½å£“ï¼ˆ_track_ramp æœƒåœ¨ <low_th æ™‚æ¸…/è¨˜éŒ„ last_low_recï¼‰
            # ä»€éº¼éƒ½ä¸åšï¼Œç›´åˆ°ä¸‹æ¬¡é›¢ä½å£“ä¸¦å‡ç ´ high_th æœƒå›åˆ° IDLE->ACTIVE æµç¨‹
            if val < self.low_th:
                # å›åˆ°ä½å£“ï¼Œä¹‹å¾Œé›¢é–‹æ™‚æœƒé‡æ–° arm
                self.fixed_state = "IDLE"
            return None

        return None

    # ================= åŸæœ¬çš„ single/double æ¨¡å¼ =================
    def _start_cycle_from(self, rec):
        self.cycle_buffer = [rec] if rec is not None else []
        ts0 = rec.get(TIME_COL) if rec else None
        self.cycle_start_ts = ts0 if pd.notna(ts0) else None
        self.timeout_alerted = False

    def _end_cycle_reset(self):
        self.cycle_start_ts = None
        self.timeout_alerted = False

    def _update_single(self, record, val):
        if self.state == "IDLE":
            if (self.ramp_start_rec is not None) and (val >= self.high_th):
                self._start_cycle_from(self.ramp_start_rec)
                self.state = "FIRST_HIGH"
            return None
        if self.state == "FIRST_HIGH":
            self.cycle_buffer.append(record)
            if val < self.low_th:
                self.state = "WAIT_SECOND_RISE"
            return None
        if self.state == "WAIT_SECOND_RISE":
            if val >= self.high_th:
                out = pd.DataFrame(self.cycle_buffer[:-1]) if self.cycle_buffer else None
                self.state = "FIRST_HIGH"
                if self.ramp_start_rec is not None:
                    self._start_cycle_from(self.ramp_start_rec)
                else:
                    self.cycle_buffer = []
                    self._end_cycle_reset()
                return out
            self.cycle_buffer.append(record)
            return None
        return None

    def _update_double(self, record, val):
        if self.state == "IDLE":
            if (self.ramp_start_rec is not None) and (val >= self.high_th):
                self._start_cycle_from(self.ramp_start_rec)
                self.state = "HIGH1"
            return None
        if self.state == "HIGH1":
            self.cycle_buffer.append(record); 
            if val < self.low_th: self.state = "LOW1"
            return None
        if self.state == "LOW1":
            self.cycle_buffer.append(record); 
            if val >= self.high_th: self.state = "HIGH2"
            return None
        if self.state == "HIGH2":
            self.cycle_buffer.append(record); 
            if val < self.low_th: self.state = "LOW2"
            return None
        if self.state == "LOW2":
            self.cycle_buffer.append(record)
            if val >= self.high_th:
                out = pd.DataFrame(self.cycle_buffer[:-1]) if self.cycle_buffer else None
                self.state = "HIGH1"
                if self.ramp_start_rec is not None:
                    self._start_cycle_from(self.ramp_start_rec)
                else:
                    self.cycle_buffer = []
                    self._end_cycle_reset()
                return out
            return None
        return None

    # ================= å…¬ç”¨å…¥å£ =================
    def update(self, record):
        val = self._val(record)
        self._track_ramp(record, val)
        if self.fixed_duration_sec and self.fixed_duration_sec > 0:
            return self._update_fixed(record, val)
        # å¦å‰‡èµ°åŸæœ¬ single/double è¦å‰‡
        out = self._update_single(record, val) if self.mode == "single" else self._update_double(record, val)
        # åœ¨ä¸€èˆ¬æ¨¡å¼ä¸‹ä¹Ÿå¯åšå³æ™‚è¶…æ™‚æª¢æŸ¥
        if self.state in ("FIRST_HIGH", "WAIT_SECOND_RISE", "HIGH1", "LOW1", "HIGH2", "LOW2"):
            self._maybe_timeout_alert(record)
        return out

# ===== holding_timeï¼ˆä¸ç­‰é–“éš”ï¼Œç·šæ€§æ’å€¼ï¼‰ =====
def _duration_above_threshold_irregular(ts: pd.Series, x: np.ndarray, thr: float) -> float:
    t = pd.to_datetime(ts).astype("int64").to_numpy() / 1e9
    if len(t) < 2: return 0.0
    total = 0.0
    for i in range(len(t) - 1):
        t0, t1 = t[i], t[i + 1]
        x0, x1 = x[i], x[i + 1]
        dt = t1 - t0
        if dt <= 0: continue
        above0, above1 = (x0 > thr), (x1 > thr)
        if above0 and above1:
            total += dt
        elif above0 != above1:
            tau = (thr - x0) * dt / (x1 - x0) if x1 != x0 else dt / 2.0
            tau = max(0.0, min(dt, tau))
            total += (dt - tau) if (not above0 and above1) else tau
    return float(total)

# ===== ç‰¹å¾µ =====
def extract_features(df: pd.DataFrame, col: str):
    if df is None or df.empty or col not in df or TIME_COL not in df:
        return None
    x = df[col].astype(float).to_numpy()
    ts = pd.to_datetime(df[TIME_COL])
    if len(x) < 2 or ts.isna().any(): return None
    if not ts.is_monotonic_increasing:
        df = df.sort_values(TIME_COL).reset_index(drop=True)
        x = df[col].astype(float).to_numpy()
        ts = pd.to_datetime(df[TIME_COL])

    x_max, x_min = float(np.max(x)), float(np.min(x))
    x_mean, x_std = float(np.mean(x)), float(np.std(x))
    x_range = float(x_max - x_min)
    total_sec = max((ts.iloc[-1] - ts.iloc[0]).total_seconds(), 1e-9)
    # slope / stability å¦‚éœ€å¯æ‰“é–‹
    holding_time = _duration_above_threshold_irregular(ts, x, thr=PRESSURE_THRESHOLD)
    return {"mean": x_mean, "std": x_std, "range": x_range, "holding_time": holding_time}
        
def on_timeout(sensor_key, duration_sec, start_ts, now_ts):
    # ä½ ä¹Ÿå¯ä»¥åœ¨é€™è£¡ï¼šå¯«å…¥å‘Šè­¦è¡¨ã€ç™¼é€šçŸ¥ã€ä¸ŸAPIç­‰
    print(f"âš ï¸ å³æ™‚å‘Šè­¦ï¼š{sensor_key} é€±æœŸå·² {duration_sec:.2f}sï¼ˆ{start_ts} â†’ {now_ts}ï¼‰")
    
# ===== è·¨æ„Ÿæ¸¬å™¨ç‰¹å¾µï¼ˆç²¾ç°¡ç¤ºç¯„ï¼Œå¯å†æ“´å……ï¼‰=====
# def build_cross_features(flat_feats: dict):
#     # æ”¶é›†å…­æ ¹çš„å‡å€¼
#     means = [flat_feats.get(f"sensor{i}_mean", 0.0) for i in range(1, 7)]
#     overall_mean = float(np.mean(means)) if len(means) else 0.0
#     # ä¾‹ï¼šæœ€å¤§-æœ€å°çš„å‡å€¼å·®ã€å‡å€¼çš„æ¨™æº–å·®ã€æ¯æ ¹ç›¸å°å…¶ä»–çš„å·®èˆ‡æ¯”
#     cross = {
#         "max_mean_diff": float(np.max(means) - np.min(means)) if means else 0.0,
#         "std_of_means": float(np.std(means)) if means else 0.0,
#     }
#     for i in range(1, 7):
#         mi = flat_feats.get(f"sensor{i}_mean", 0.0)
#         cross[f"sensor{i}_diff_mean"] = mi - overall_mean
#         cross[f"sensor{i}_ratio_mean"] = (mi / overall_mean) if overall_mean != 0 else 0.0
#     # æ’åï¼ˆ1~6ï¼Œ1=æœ€ä½ã€6=æœ€é«˜ï¼‰
#     ranks = pd.Series(means).rank(method="average").tolist()
#     for i in range(1, 7):
#         cross[f"sensor{i}_rank_mean"] = ranks[i-1]
#     return cross

def ensure_merged_index_header(path: str, model_feature_names: list[str]):
    if not os.path.exists(path):
        cols = ["cycle_id", "start_ts", "end_ts"]
        # æ¨¡å‹ç‰¹å¾µï¼ˆä¿å­˜ä¾¿æ–¼è¿½æº¯ï¼‰
        cols += list(model_feature_names)
        # æ¯æ ¹çš„é æ¸¬èˆ‡é¡¯ç¤ºåç¨±
        for i in range(1, 7):
            cols += [f"pred_sensor{i}", f"pred_name_sensor{i}"]
        pd.DataFrame(columns=cols).to_csv(path, index=False, encoding="utf-8-sig")
        
def label_name(cls_value: int) -> str:
    return LABEL_MAP.get(int(cls_value), str(cls_value))

def extract_features_all(cycle_dict: dict):
    """
    cycle_dict: { "psr_val_0": df0, ..., "psr_val_5": df5 }
    å›å‚³: åªæœ‰å…­æ ¹æ„Ÿæ¸¬å™¨çš„å–®æ ¹ç‰¹å¾µï¼ˆmean/std/range/holding_timeï¼‰ï¼Œä¸å«è·¨æ„Ÿæ¸¬å™¨ç‰¹å¾µ
    """
    flat_feats = {}
    for i in range(6):
        key = f"psr_val_{i}"
        df = cycle_dict.get(key)
        f = extract_features(df, key) if df is not None else None
        if f:
            for k, v in f.items():
                flat_feats[f"sensor{i+1}_{k}"] = v
        else:
            # è©²æ„Ÿæ¸¬å™¨æ²’æœ‰è³‡æ–™å°±è£œ 0
            for k in FEATURE_COLS:
                flat_feats[f"sensor{i+1}_{k}"] = 0.0

    return flat_feats


# ===== ä¸»æµç¨‹ =====
def main():
    detectors = {
        key: CycleDetector(low_th=LOW_END, high_th=HIGH_ON, sensor_key=key,
                           mode=MODE_MAP[key], max_cycle_sec=MAX_CYCLE_SEC,
                           on_timeout=on_timeout, fixed_duration_sec=11.0)
        for key in MODE_MAP.keys()
    }

    cycle_counters = 1
    model = joblib.load("models/rf_multioutput.pkl")   # å–®ä¸€å…­åˆä¸€æ¨¡å‹

    features_index_path = os.path.join(OUTPUT_DIR, "features_index.csv")
    if not os.path.exists(features_index_path):
        pd.DataFrame(columns=[
            "cycle_id",
            *(f"sensor{i+1}_{c}" for i in range(6) for c in FEATURE_COLS),
            *(f"pred_sensor{i+1}" for i in range(6))
        ]).to_csv(features_index_path, index=False, encoding="utf-8-sig")

    # åˆå§‹åŒ– pending_cycles
    pending_cycles = {f"psr_val_{i}": None for i in range(6)}

    for record in simulate_data_stream():
        for key, det in detectors.items():
            cycle_df = det.update(record)
            if cycle_df is not None and not cycle_df.empty:
                pending_cycles[key] = cycle_df

        # Debug: ç›®å‰æœ‰å¹¾æ ¹æ„Ÿæ¸¬å™¨å·²å®Œæˆé€±æœŸ
        ready_count = sum(df is not None and not df.empty for df in pending_cycles.values())
        print(f"ğŸ”„ å·²å®Œæˆé€±æœŸçš„æ„Ÿæ¸¬å™¨æ•¸é‡: {ready_count}/6", end="\r")

        # ç­‰åˆ°å…­æ ¹éƒ½æœ‰ cycle â†’ æ‰åšé æ¸¬
        if all(df is not None and not df.empty for df in pending_cycles.values()):
            feats = extract_features_all(pending_cycles)
            X_row = pd.DataFrame([feats]).reindex(columns=model.feature_names_in_, fill_value=0.0)

            y_pred = model.predict(X_row)[0]

            row = {
                "cycle_id": cycle_counters,
                **feats,
                **{f"pred_sensor{i+1}": int(y_pred[i]) for i in range(6)}
            }

            pd.DataFrame([row]).to_csv(
                features_index_path, mode="a", header=False, index=False, encoding="utf-8-sig"
            )

            print(f"\nâœ… é€±æœŸ #{cycle_counters} ï½œé æ¸¬çµæœ: {y_pred}")

            cycle_counters += 1

            # é‡ç½®ï¼Œç­‰ä¸‹ä¸€è¼ª
            pending_cycles = {f"psr_val_{i}": None for i in range(6)}

if __name__ == "__main__":
    main()
