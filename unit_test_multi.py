import os
import numpy as np
import pandas as pd
import joblib
from dotenv import load_dotenv
from modules import CycleDetector, ProbVoteBuffer, MultiLeakArbiter, send_sms, error_log, mysql_log, mqtt_log
from config.constants import *

load_dotenv()

USERNAME = os.getenv("TWSMS_USER")
PASSWORD = os.getenv("TWSMS_PASS")
API = os.getenv("TWSMS_API")
MOBILE = os.getenv("TWSMS_MOBILE")

MYSQL_HOST = os.getenv("MYSQL_HOST")
MYSQL_USER = os.getenv("MYSQL_USER")
MYSQL_PASSWORD = os.getenv("MYSQL_PASSWORD")
POLICY_DB = os.getenv("POLICY_DB")
POLICY_TABLE = os.getenv("POLICY_TABLE")
DATA_DB = os.getenv("DATA_DB")
TABLE_NAME = os.getenv("TABLE_NAME")

# ===== åƒæ•¸ =====
OUTPUT_DIR = "cycles_out"
os.makedirs(OUTPUT_DIR, exist_ok=True)
MODELS_DIR = "models_many_normal"
CYCLE_ERROR = 0

MODEL_PATH = "models/rf_multioutput.pkl"

# ===== æ™‚é–“ & è³‡æ–™æµ =====
def _to_datetime(val):
    try:
        ts = pd.to_datetime(val, errors="coerce")
        if pd.notna(ts): return ts
    except Exception:
        pass
    try:
        f = pd.to_numeric(val, errors="coerce")
        if pd.isna(f): return None
        if f > 1e15:   return pd.to_datetime(f, unit="ns", errors="coerce")
        elif f > 1e14: return pd.to_datetime(f, unit="us", errors="coerce")
        elif f > 1e11: return pd.to_datetime(f, unit="ms", errors="coerce")
        elif f > 1e9:  return pd.to_datetime(f, unit="s",  errors="coerce")
        else:          return pd.to_datetime(f, unit="s",  errors="coerce")
    except Exception:
        return None

def simulate_data_stream():
    df = pd.read_csv('row_data/å…©æ ¹/7åœˆ/ç¬¬ä¸€å››æ ¹ä¸ƒåœˆ_1.csv', encoding="utf-8-sig")
    for _, row in df.iterrows():
        record = {
            'si_ts': _to_datetime(row['si_ts']),
            'psr_val_0': float(row['psr_val_0']),
            'psr_val_1': float(row['psr_val_1']),
            'psr_val_2': float(row['psr_val_2']),
            'psr_val_3': float(row['psr_val_3']),
            'psr_val_4': float(row['psr_val_4']),
            'psr_val_5': float(row['psr_val_5']),
        }
        # time.sleep(0.02)
        yield record

# ===== holding_timeï¼ˆä¸ç­‰é–“éš”ï¼Œç·šæ€§æ’å€¼ï¼‰ =====
def _duration_above_threshold_irregular(ts: pd.Series, x: np.ndarray, thr: float) -> float:
    t = pd.to_datetime(ts).astype("int64").to_numpy() / 1e9
    if len(t) < 2: return 0.0
    total = 0.0
    for i in range(len(t) - 1):
        t0, t1 = t[i], t[i + 1]
        x0, x1 = x[i], x[i + 1]
        dt = t1 - t0
        if dt <= 0: continue
        above0, above1 = (x0 > thr), (x1 > thr)
        if above0 and above1:
            total += dt
        elif above0 != above1:
            tau = (thr - x0) * dt / (x1 - x0) if x1 != x0 else dt / 2.0
            tau = max(0.0, min(dt, tau))
            total += (dt - tau) if (not above0 and above1) else tau
    return float(total)

# ===== ç‰¹å¾µ =====
def extract_features(df: pd.DataFrame, col: str):
    if df is None or df.empty or col not in df or TIME_COL not in df:
        return None
    x = df[col].astype(float).to_numpy()
    ts = pd.to_datetime(df[TIME_COL])
    if len(x) < 2 or ts.isna().any(): return None
    if not ts.is_monotonic_increasing:
        df = df.sort_values(TIME_COL).reset_index(drop=True)
        x = df[col].astype(float).to_numpy()
        ts = pd.to_datetime(df[TIME_COL])

    x_max, x_min = float(np.max(x)), float(np.min(x))
    x_mean, x_std = float(np.mean(x)), float(np.std(x))
    x_range = float(x_max - x_min)
    total_sec = max((ts.iloc[-1] - ts.iloc[0]).total_seconds(), 1e-9)
    # slope / stability å¦‚éœ€å¯æ‰“é–‹
    holding_time = _duration_above_threshold_irregular(ts, x, thr=PRESSURE_THRESHOLD)
    return {"mean": x_mean, "std": x_std, "range": x_range, "holding_time": holding_time}
        
# ===== è·¨æ„Ÿæ¸¬å™¨ç‰¹å¾µï¼ˆç²¾ç°¡ç¤ºç¯„ï¼Œå¯å†æ“´å……ï¼‰=====
# def build_cross_features(flat_feats: dict):
#     # æ”¶é›†å…­æ ¹çš„å‡å€¼
#     means = [flat_feats.get(f"sensor{i}_mean", 0.0) for i in range(1, 7)]
#     overall_mean = float(np.mean(means)) if len(means) else 0.0
#     # ä¾‹ï¼šæœ€å¤§-æœ€å°çš„å‡å€¼å·®ã€å‡å€¼çš„æ¨™æº–å·®ã€æ¯æ ¹ç›¸å°å…¶ä»–çš„å·®èˆ‡æ¯”
#     cross = {
#         "max_mean_diff": float(np.max(means) - np.min(means)) if means else 0.0,
#         "std_of_means": float(np.std(means)) if means else 0.0,
#     }
#     for i in range(1, 7):
#         mi = flat_feats.get(f"sensor{i}_mean", 0.0)
#         cross[f"sensor{i}_diff_mean"] = mi - overall_mean
#         cross[f"sensor{i}_ratio_mean"] = (mi / overall_mean) if overall_mean != 0 else 0.0
#     # æ’åï¼ˆ1~6ï¼Œ1=æœ€ä½ã€6=æœ€é«˜ï¼‰
#     ranks = pd.Series(means).rank(method="average").tolist()
#     for i in range(1, 7):
#         cross[f"sensor{i}_rank_mean"] = ranks[i-1]
#     return cross

def ensure_merged_index_header(path: str, model_feature_names: list[str]):
    if not os.path.exists(path):
        cols = ["cycle_id", "start_ts", "end_ts"]
        # æ¨¡å‹ç‰¹å¾µï¼ˆä¿å­˜ä¾¿æ–¼è¿½æº¯ï¼‰
        cols += list(model_feature_names)
        # æ¯æ ¹çš„é æ¸¬èˆ‡é¡¯ç¤ºåç¨±
        for i in range(1, 7):
            cols += [f"pred_sensor{i}", f"pred_name_sensor{i}"]
        pd.DataFrame(columns=cols).to_csv(path, index=False, encoding="utf-8-sig")
        
def label_name(cls_value: int) -> str:
    return LABEL_MAP.get(int(cls_value), str(cls_value))

def extract_features_all(cycle_dict: dict):
    """
    cycle_dict: { "psr_val_0": df0, ..., "psr_val_5": df5 }
    å›å‚³: åªæœ‰å…­æ ¹æ„Ÿæ¸¬å™¨çš„å–®æ ¹ç‰¹å¾µï¼ˆmean/std/range/holding_timeï¼‰ï¼Œä¸å«è·¨æ„Ÿæ¸¬å™¨ç‰¹å¾µ
    """
    flat_feats = {}
    for i in range(6):
        key = f"psr_val_{i}"
        df = cycle_dict.get(key)
        f = extract_features(df, key) if df is not None else None
        if f:
            for k, v in f.items():
                flat_feats[f"sensor{i+1}_{k}"] = v
        else:
            # è©²æ„Ÿæ¸¬å™¨æ²’æœ‰è³‡æ–™å°±è£œ 0
            for k in FEATURE_COLS:
                flat_feats[f"sensor{i+1}_{k}"] = 0.0

    return flat_feats


# ===== ä¸»æµç¨‹ =====
def main():
    global CYCLE_ERROR
    detectors = {
        key: CycleDetector(low_th=LOW_END, high_th=HIGH_ON, sensor_key=key, mode=MODE_MAP[key], fixed_duration_sec=11.0)
        for key in MODE_MAP.keys()
    }

    cycle_counters = 1
    model = joblib.load(MODELS_DIR)   # å–®ä¸€å…­åˆä¸€æ¨¡å‹

    features_index_path = os.path.join(OUTPUT_DIR, "features_index.csv")
    if not os.path.exists(features_index_path):
        pd.DataFrame(columns=[
            "cycle_id",
            *(f"sensor{i+1}_{c}" for i in range(6) for c in FEATURE_COLS),
            *(f"pred_sensor{i+1}" for i in range(6))
        ]).to_csv(features_index_path, index=False, encoding="utf-8-sig")

    # åˆå§‹åŒ– pending_cycles
    pending_cycles = {f"psr_val_{i}": None for i in range(6)}

    for record in simulate_data_stream():
        for key, det in detectors.items():
            cycle_df = det.update(record)
            if cycle_df is not None and not cycle_df.empty:
                pending_cycles[key] = cycle_df
                
            sensor_name = SENSOR_NAME[key]
            
            if det.last_cycle_valid is False:
                CYCLE_ERROR += 1
                if CYCLE_ERROR >= 3:
                    # send_sms(USERNAME, PASSWORD, API, MOBILE, f"âš ï¸ {sensor_name} é€£çºŒä¸‰æ¬¡ç•°å¸¸ï¼Œè«‹æª¢æŸ¥ç³»çµ±ï¼")
                    print(f"âš ï¸ {sensor_name} ç•°å¸¸çª—ï¼Œç•¥éï¼ˆ{det.last_cycle_reason}ï¼‰") # åŠ å…¥counter
                continue

        # Debug: ç›®å‰æœ‰å¹¾æ ¹æ„Ÿæ¸¬å™¨å·²å®Œæˆé€±æœŸ
        ready_count = sum(df is not None and not df.empty for df in pending_cycles.values())
        print(f"ğŸ”„ å·²å®Œæˆé€±æœŸçš„æ„Ÿæ¸¬å™¨æ•¸é‡: {ready_count}/6", end="\r")

        # ç­‰åˆ°å…­æ ¹éƒ½æœ‰ cycle â†’ æ‰åšé æ¸¬
        if all(df is not None and not df.empty for df in pending_cycles.values()):
            feats = extract_features_all(pending_cycles)
            X_row = pd.DataFrame([feats]).reindex(columns=model.feature_names_in_, fill_value=0.0)

            y_pred = model.predict(X_row)[0]

            row = {
                "cycle_id": cycle_counters,
                **feats,
                **{f"pred_sensor{i+1}": int(y_pred[i]) for i in range(6)}
            }

            pd.DataFrame([row]).to_csv(
                features_index_path, mode="a", header=False, index=False, encoding="utf-8-sig"
            )

            print(f"\nâœ… é€±æœŸ #{cycle_counters} ï½œé æ¸¬çµæœ: {y_pred}")

            cycle_counters += 1

            # é‡ç½®ï¼Œç­‰ä¸‹ä¸€è¼ª
            pending_cycles = {f"psr_val_{i}": None for i in range(6)}

if __name__ == "__main__":
    main()
